import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import praw
import instaloader
import os

# Ø¥Ø¹Ø¯Ø§Ø¯ Reddit
reddit = praw.Reddit(
    client_id="qfRizUHOzPM5DXtO8a3UoQ",
    client_secret="nrklg9cnDPaqu0Vzfa_RdOk2lETt3A",
    username="Few_Measurement8753",
    password="4248Ù‚Ø©Ø´Ø©Ù‚",
    user_agent="Reddit scraper by u/Few_Measurement8753"
)

# Ø¥Ø¹Ø¯Ø§Ø¯ Instagram (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù„Ù Ø§Ù„Ø¬Ù„Ø³Ø©)
SESSION_FILE = "session-frfrre45"
loader = instaloader.Instaloader()

# Ø¯Ø§Ù„Ø© Ø³Ø­Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Reddit
def scrape_reddit(username):
    try:
        user = reddit.redditor(username)
        name = user.name
        try:
            bio = user.subreddit.public_description
        except:
            bio = "N/A"
        karma = user.link_karma + user.comment_karma
        created = str(user.created_utc)
        return {
            "Platform": "Reddit",
            "Account Name": name,
            "Account Bio": bio,
            "Karma": karma,
            "Created At": created,
            "Status": "Active",
            "Link": f"https://www.reddit.com/user/{username}/"
        }
    except:
        return {
            "Platform": "Reddit",
            "Account Name": "N/A",
            "Account Bio": "N/A",
            "Karma": "N/A",
            "Created At": "N/A",
            "Status": "Failed or Not Found",
            "Link": f"https://www.reddit.com/user/{username}/"
        }

# Ø¯Ø§Ù„Ø© Ø³Ø­Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Instagram
def scrape_instagram(username):
    try:
        loader.load_session_from_file("frfrre45", SESSION_FILE)
        profile = instaloader.Profile.from_username(loader.context, username)
        return {
            "Platform": "Instagram",
            "Account Name": profile.username,
            "Account Bio": profile.biography,
            "Followers": profile.followers,
            "Following": profile.followees,
            "Posts": profile.mediacount,
            "Created": profile.date_joined.strftime('%Y-%m-%d') if profile.date_joined else "N/A",
            "Status": "Active",
            "Link": f"https://www.instagram.com/{username}/"
        }
    except:
        return {
            "Platform": "Instagram",
            "Account Name": "N/A",
            "Account Bio": "N/A",
            "Followers": "N/A",
            "Following": "N/A",
            "Posts": "N/A",
            "Created": "N/A",
            "Status": "Failed or Not Found",
            "Link": f"https://www.instagram.com/{username}/"
        }

# Ø¯Ø§Ù„Ø© Ø³Ø­Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† TikTok
def scrape_tiktok(username):
    url = f"https://www.tiktok.com/@{username}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
    }
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            return {
                "Platform": "TikTok",
                "Account Name": username,
                "Account Bio": "N/A",
                "Followers": "Ø¬Ø§Ø±Ù Ø§Ù„ØªØ­Ø¯ÙŠØ«",
                "Following": "Ø¬Ø§Ø±Ù Ø§Ù„ØªØ­Ø¯ÙŠØ«",
                "Posts": "Ø¬Ø§Ø±Ù Ø§Ù„ØªØ­Ø¯ÙŠØ«",
                "Created": "N/A",
                "Status": "Active",
                "Link": url
            }
        else:
            raise Exception("Not found")
    except:
        return {
            "Platform": "TikTok",
            "Account Name": "N/A",
            "Account Bio": "N/A",
            "Followers": "N/A",
            "Following": "N/A",
            "Posts": "N/A",
            "Created": "N/A",
            "Status": "Failed or Not Found",
            "Link": url
        }

# ÙˆØ§Ø¬Ù‡Ø© Streamlit
st.title("ğŸ” Social Account Scraper")
platform = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ù…Ù†ØµØ©:", ["Instagram", "Reddit", "TikTok"])
input_text = st.text_area("Ø£Ø¯Ø®Ù„ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª (ÙƒÙ„ Ø±Ø§Ø¨Ø· ÙÙŠ Ø³Ø·Ø±):")

if st.button("Ø§Ø¨Ø¯Ø£"):
    st.info(f"Ø¬Ø§Ø±ÙŠ Ø³Ø­Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† {platform}...")
    results = []
    links = [line.strip() for line in input_text.split("\n") if line.strip()]

    for link in links:
        if platform == "Reddit":
            username = link.rstrip("/").split("/")[-1]
            results.append(scrape_reddit(username))
        elif platform == "Instagram":
            username = link.rstrip("/").split("/")[-1]
            results.append(scrape_instagram(username))
        elif platform == "TikTok":
            username = link.rstrip("/").split("@")[1] if "@" in link else link.rstrip("/").split("/")[-1]
            results.append(scrape_tiktok(username))

    if results:
        df = pd.DataFrame(results)
        st.markdown("### ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
        st.dataframe(df)
        st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ CSV", df.to_csv(index=False).encode('utf-8'), "results.csv", "text/csv")
