import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import praw

# ---------------------- Ø¯Ø§Ù„Ø© Telegram ----------------------
def scrape_telegram(url):
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, "html.parser")

        name = soup.find("meta", property="og:title")
        bio = soup.find("meta", property="og:description")

        return {
            "Platform": "Telegram",
            "Account Name": name["content"] if name else "N/A",
            "Account Bio": bio["content"] if bio else "N/A",
            "Status": "Active",
            "Link": url
        }
    except Exception:
        return {
            "Platform": "Telegram",
            "Account Name": "N/A",
            "Account Bio": "N/A",
            "Status": "Failed or Not Found",
            "Link": url
        }

# ---------------------- Ø¯Ø§Ù„Ø© Reddit ----------------------
def scrape_reddit(username):
    try:
        reddit = praw.Reddit(
            client_id="qfRizUHozPM5DXtO8a3UoQ",
            client_secret="nrklg9cnDPaqu0Vzfa_RdOk2lETt3A",
            user_agent="Reddit user data scraper by /u/Few_Measurement8753"
        )
        user = reddit.redditor(username)
        bio = user.subreddit.public_description if user.subreddit else "N/A"
        name = user.name
        link = f"https://www.reddit.com/user/{username}/"

        return {
            "Platform": "Reddit",
            "Account Name": name,
            "Account Bio": bio,
            "Status": "Active",
            "Link": link
        }
    except Exception:
        return {
            "Platform": "Reddit",
            "Account Name": "N/A",
            "Account Bio": "N/A",
            "Status": "Failed or Not Found",
            "Link": f"https://www.reddit.com/user/{username}/"
        }

# ---------------------- ÙˆØ§Ø¬Ù‡Ø© Streamlit ----------------------
st.set_page_config(page_title="Social Account Scraper", layout="centered")
st.title("ğŸ” Social Account Scraper")

platform = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ù…Ù†ØµØ©:", ["Telegram", "Reddit"])
input_text = st.text_area("Ø£Ø¯Ø®Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„Ø­Ø³Ø§Ø¨:", placeholder="Ù…Ø«Ø§Ù„: https://t.me/username Ø£Ùˆ https://www.reddit.com/user/username")

if st.button("Ø§Ø¨Ø¯Ø£"):
    st.write("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø³Ø­Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†", platform, "...")
    if platform == "Telegram":
        result = scrape_telegram(input_text)
    elif platform == "Reddit":
        username = input_text.strip().split("/")[-1]
        result = scrape_reddit(username)

    df = pd.DataFrame([result])
    st.subheader("ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
    st.table(df)

    st.download_button(
        label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ CSV",
        data=df.to_csv(index=False),
        file_name="scraped_results.csv",
        mime="text/csv"
    )
