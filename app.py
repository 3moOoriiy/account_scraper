import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import praw

# Ø¥Ø¹Ø¯Ø§Ø¯ API Ù„Ù€ Reddit
reddit = praw.Reddit(
    client_id="qfRizUHOzPM5DXtO8a3UoQ",
    client_secret="nrklg9cnDPaqu0Vzfa_RdOk2lETt3A",
    user_agent="Reddit user data scraper by /u/Few_Measurement8753"
)

# ==============================
# Ø¯Ø§Ù„Ø© Telegram
# ==============================
def scrape_telegram(link):
    try:
        response = requests.get(link)
        soup = BeautifulSoup(response.content, "html.parser")
        name = soup.find("meta", property="og:title")["content"] if soup.find("meta", property="og:title") else "N/A"
        bio = soup.find("meta", property="og:description")["content"] if soup.find("meta", property="og:description") else "N/A"
        return {
            "Platform": "Telegram",
            "Account Name": name,
            "Account Bio": bio,
            "Status": "Active",
            "Link": link
        }
    except:
        return {
            "Platform": "Telegram",
            "Account Name": "N/A",
            "Account Bio": "N/A",
            "Status": "Failed or Not Found",
            "Link": link
        }

# ==============================
# Ø¯Ø§Ù„Ø© Reddit
# ==============================
def scrape_reddit(link):
    try:
        username = link.strip("/").split("/")[-1]
        user = reddit.redditor(username)
        name = user.name
        bio = user.subreddit.public_description if user.subreddit else "N/A"
        return {
            "Platform": "Reddit",
            "Account Name": name,
            "Account Bio": bio,
            "Status": "Active",
            "Link": link
        }
    except:
        return {
            "Platform": "Reddit",
            "Account Name": "N/A",
            "Account Bio": "N/A",
            "Status": "Failed or Not Found",
            "Link": link
        }

# ==============================
# Streamlit UI
# ==============================
st.title("ğŸ” Social Account Scraper")

platform = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ù…Ù†ØµØ©:", ["Telegram", "Reddit"])
links_input = st.text_area("ğŸ“¥ Ø£Ø¯Ø®Ù„ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª (ÙƒÙ„ Ø±Ø§Ø¨Ø· ÙÙŠ Ø³Ø·Ø±)")

if st.button("Ø§Ø¨Ø¯Ø£"):
    st.write(f"Ø¬Ø§Ø±ÙŠ Ø³Ø­Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† {platform}...")
    links = [link.strip() for link in links_input.splitlines() if link.strip()]
    results = []
    for link in links:
        if platform == "Telegram":
            results.append(scrape_telegram(link))
        elif platform == "Reddit":
            results.append(scrape_reddit(link))
    
    df = pd.DataFrame(results)
    st.subheader("ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
    st.dataframe(df)
    st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ CSV", data=df.to_csv(index=False), file_name="account_data.csv", mime="text/csv")
