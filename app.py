import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import praw
import datetime
from instagramy import InstagramUser

# Ø¥Ø¹Ø¯Ø§Ø¯ Reddit API
reddit = praw.Reddit(
    client_id="qfRizUHOzPM5DXtO8a3UoQ",
    client_secret="nrklg9cnDPaqu0Vzfa_RdOk2lETt3A",
    user_agent="Reddit scraper by u/Few_Measurement8753",
    username="Few_Measurement8753",
    password="Ø´Ø©Ù‚Ø´Ø©Ù‚4248"
)

# Ø¯Ø§Ù„Ø© Reddit
def scrape_reddit(username):
    try:
        user = reddit.redditor(username)
        name = user.name
        bio = getattr(user.subreddit, "public_description", "N/A") if hasattr(user, "subreddit") else "N/A"
        karma = user.link_karma + user.comment_karma
        created = datetime.datetime.fromtimestamp(user.created_utc).strftime("%Y-%m-%d")
        return {
            "Platform": "Reddit",
            "Account Name": name,
            "Account Bio": bio,
            "Followers": karma,
            "Following": "N/A",
            "Posts": "N/A",
            "Created": created,
            "Status": "Active",
            "Link": f"https://www.reddit.com/user/{username}/"
        }
    except:
        return {
            "Platform": "Reddit",
            "Account Name": "N/A",
            "Account Bio": "N/A",
            "Followers": "N/A",
            "Following": "N/A",
            "Posts": "N/A",
            "Created": "N/A",
            "Status": "Failed or Not Found",
            "Link": f"https://www.reddit.com/user/{username}/"
        }

# Ø¯Ø§Ù„Ø© Telegram
def scrape_telegram(url):
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.content, 'html.parser')
        name = soup.find("meta", property="og:title")
        bio = soup.find("meta", property="og:description")
        return {
            "Platform": "Telegram",
            "Account Name": name["content"] if name else "N/A",
            "Account Bio": bio["content"] if bio else "N/A",
            "Followers": "N/A",
            "Following": "N/A",
            "Posts": "N/A",
            "Created": "N/A",
            "Status": "Active",
            "Link": url
        }
    except:
        return {
            "Platform": "Telegram",
            "Account Name": "N/A",
            "Account Bio": "N/A",
            "Followers": "N/A",
            "Following": "N/A",
            "Posts": "N/A",
            "Created": "N/A",
            "Status": "Failed or Not Found",
            "Link": url
        }

# Ø¯Ø§Ù„Ø© Instagram
def scrape_instagram(username):
    try:
        user = InstagramUser(username)
        return {
            "Platform": "Instagram",
            "Account Name": user.fullname,
            "Account Bio": user.biography,
            "Followers": user.followers,
            "Following": user.following,
            "Posts": user.number_of_posts,
            "Created": "N/A",
            "Status": "Active",
            "Link": f"https://www.instagram.com/{username}/"
        }
    except:
        return {
            "Platform": "Instagram",
            "Account Name": "N/A",
            "Account Bio": "N/A",
            "Followers": "N/A",
            "Following": "N/A",
            "Posts": "N/A",
            "Created": "N/A",
            "Status": "Failed or Not Found",
            "Link": f"https://www.instagram.com/{username}/"
        }

# Streamlit ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
st.title("ğŸ” Social Account Scraper")
platform = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ù…Ù†ØµØ©:", ["Telegram", "Reddit", "Instagram"])
input_text = st.text_area("ğŸ“¥ Ø£Ø¯Ø®Ù„ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª (ÙƒÙ„ Ø±Ø§Ø¨Ø· ÙÙŠ Ø³Ø·Ø±):")

if st.button("Ø§Ø¨Ø¯Ø£"):
    links = [line.strip() for line in input_text.split("\n") if line.strip()]
    results = []

    for link in links:
        if platform == "Reddit":
            username = link.split("/")[-2] if link.endswith("/") else link.split("/")[-1]
            results.append(scrape_reddit(username))
        elif platform == "Telegram":
            results.append(scrape_telegram(link))
        elif platform == "Instagram":
            username = link.split("/")[-2] if link.endswith("/") else link.split("/")[-1]
            results.append(scrape_instagram(username))

    df = pd.DataFrame(results)
    st.markdown("### ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
    st.dataframe(df)
    st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ CSV", df.to_csv(index=False), file_name="results.csv", mime="text/csv")
